{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torchaudio\n",
    "import json\n",
    "# from asccd import encoding, preanalysis\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "from transformers import Data2VecAudioModel,Data2VecAudioConfig,Wav2Vec2Processor,AutoModel,AutoConfig\n",
    "# from models.HiFiGAN_Generator import HiFiGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SpeechAutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 2682/2682 [00:00<00:00, 6887.36it/s] \n",
      "Resolving data files: 100%|██████████| 87/87 [00:00<00:00, 152043.52it/s]\n",
      "Resolving data files: 100%|██████████| 97/97 [00:00<00:00, 143104.99it/s]\n",
      "Using custom data configuration LibriSpeech-520ecad719a1cd51\n",
      "Reusing dataset text (./cache/datasets/librispeech_asr/text/LibriSpeech-520ecad719a1cd51/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
      "Resolving data files: 100%|██████████| 2682/2682 [00:00<00:00, 20048.30it/s]\n",
      "Resolving data files: 100%|██████████| 87/87 [00:00<00:00, 150352.06it/s]\n",
      "Resolving data files: 100%|██████████| 97/97 [00:00<00:00, 156902.23it/s]\n",
      "Using custom data configuration LibriSpeech-520ecad719a1cd51\n",
      "Reusing dataset text (./cache/datasets/librispeech_asr/text/LibriSpeech-520ecad719a1cd51/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
      "Resolving data files: 100%|██████████| 2682/2682 [00:00<00:00, 7164.66it/s]\n",
      "Resolving data files: 100%|██████████| 87/87 [00:00<00:00, 138746.94it/s]\n",
      "Resolving data files: 100%|██████████| 97/97 [00:00<00:00, 241166.26it/s]\n",
      "Using custom data configuration LibriSpeech-520ecad719a1cd51\n",
      "Reusing dataset text (./cache/datasets/librispeech_asr/text/LibriSpeech-520ecad719a1cd51/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
      "  0%|          | 0/1326 [00:00<?, ?ex/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'audio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/lyn/speech_autoencoder/resynthesis.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.192.122/home/lyn/speech_autoencoder/resynthesis.ipynb#ch0000003vscode-remote?line=19'>20</a>\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mLibriSpeech(\u001b[39m16\u001b[39m, \u001b[39m16\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.192.122/home/lyn/speech_autoencoder/resynthesis.ipynb#ch0000003vscode-remote?line=20'>21</a>\u001b[0m \u001b[39m# dataset.prepare_data()\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.192.122/home/lyn/speech_autoencoder/resynthesis.ipynb#ch0000003vscode-remote?line=21'>22</a>\u001b[0m dataset\u001b[39m.\u001b[39;49msetup()\n",
      "File \u001b[0;32m~/speech_autoencoder/dataset.py:122\u001b[0m, in \u001b[0;36mLibriSpeech.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=116'>117</a>\u001b[0m \u001b[39m# for k,v in self.splits.items():\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=117'>118</a>\u001b[0m \u001b[39m#     self.splits[k] = v.map(self.prepare_batch,remove_columns=v.column_names)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=118'>119</a>\u001b[0m \u001b[39m# for k,v in self.splits.items():\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=119'>120</a>\u001b[0m \u001b[39m#     self.splits[k] = v.map(lambda x: self.processor(x,padding=True,pad_to_multiple_of = 320, return_tensors=\"pt\"),batched=True)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=120'>121</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=121'>122</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplits[k] \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m    <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=122'>123</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_array, remove_columns\u001b[39m=\u001b[39;49mv\u001b[39m.\u001b[39;49mcolumn_names, batched\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py:1955\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1951'>1952</a>\u001b[0m disable_tqdm \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1953'>1954</a>\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m num_proc \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1954'>1955</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_single(\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1955'>1956</a>\u001b[0m         function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1956'>1957</a>\u001b[0m         with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1957'>1958</a>\u001b[0m         with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1958'>1959</a>\u001b[0m         input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1959'>1960</a>\u001b[0m         batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1960'>1961</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1961'>1962</a>\u001b[0m         drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1962'>1963</a>\u001b[0m         remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1963'>1964</a>\u001b[0m         keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1964'>1965</a>\u001b[0m         load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1965'>1966</a>\u001b[0m         cache_file_name\u001b[39m=\u001b[39;49mcache_file_name,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1966'>1967</a>\u001b[0m         writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1967'>1968</a>\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1968'>1969</a>\u001b[0m         disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1969'>1970</a>\u001b[0m         fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1970'>1971</a>\u001b[0m         new_fingerprint\u001b[39m=\u001b[39;49mnew_fingerprint,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1971'>1972</a>\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1972'>1973</a>\u001b[0m         desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1973'>1974</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1974'>1975</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1976'>1977</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[0;32m~/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py:520\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=517'>518</a>\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=518'>519</a>\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=519'>520</a>\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=520'>521</a>\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=521'>522</a>\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=522'>523</a>\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py:487\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=479'>480</a>\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=480'>481</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=481'>482</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=482'>483</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=483'>484</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=484'>485</a>\u001b[0m }\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=485'>486</a>\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=486'>487</a>\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=487'>488</a>\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=488'>489</a>\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/GCX/lib/python3.9/site-packages/datasets/fingerprint.py:458\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/fingerprint.py?line=451'>452</a>\u001b[0m             kwargs[fingerprint_name] \u001b[39m=\u001b[39m update_fingerprint(\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/fingerprint.py?line=452'>453</a>\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fingerprint, transform, kwargs_for_fingerprint\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/fingerprint.py?line=453'>454</a>\u001b[0m             )\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/fingerprint.py?line=455'>456</a>\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/fingerprint.py?line=457'>458</a>\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/fingerprint.py?line=459'>460</a>\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/fingerprint.py?line=461'>462</a>\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py:2320\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2317'>2318</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m batched:\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2318'>2319</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pbar):\n\u001b[0;32m-> <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2319'>2320</a>\u001b[0m         example \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[39m=\u001b[39;49moffset)\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2320'>2321</a>\u001b[0m         \u001b[39mif\u001b[39;00m update_data:\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2321'>2322</a>\u001b[0m             \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py:2220\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2217'>2218</a>\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2218'>2219</a>\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2219'>2220</a>\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2220'>2221</a>\u001b[0m \u001b[39mif\u001b[39;00m update_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2221'>2222</a>\u001b[0m     \u001b[39m# Check if the function returns updated examples\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2222'>2223</a>\u001b[0m     update_data \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(processed_inputs, (Mapping, pa\u001b[39m.\u001b[39mTable))\n",
      "File \u001b[0;32m~/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py:1915\u001b[0m, in \u001b[0;36mDataset.map.<locals>.decorate.<locals>.decorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1910'>1911</a>\u001b[0m decorated_item \u001b[39m=\u001b[39m (\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1911'>1912</a>\u001b[0m     Example(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m batched \u001b[39melse\u001b[39;00m Batch(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1912'>1913</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1913'>1914</a>\u001b[0m \u001b[39m# Use the LazyDict internally, while mapping the function\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1914'>1915</a>\u001b[0m result \u001b[39m=\u001b[39m f(decorated_item, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1915'>1916</a>\u001b[0m \u001b[39m# Return a standard dict\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=1916'>1917</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, LazyDict) \u001b[39melse\u001b[39;00m result\n",
      "File \u001b[0;32m~/speech_autoencoder/dataset.py:98\u001b[0m, in \u001b[0;36mLibriSpeech.get_array\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=95'>96</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_array\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m     <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=96'>97</a>\u001b[0m     \u001b[39mbreakpoint\u001b[39m()\n\u001b[0;32m---> <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=97'>98</a>\u001b[0m     audio \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39;49m\u001b[39maudio\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=98'>99</a>\u001b[0m     batch[\u001b[39m'\u001b[39m\u001b[39minput_values\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m audio[\u001b[39m'\u001b[39m\u001b[39marray\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=99'>100</a>\u001b[0m     batch[\u001b[39m\"\u001b[39m\u001b[39minput_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batch[\u001b[39m\"\u001b[39m\u001b[39minput_values\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py:115\u001b[0m, in \u001b[0;36mExample.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=113'>114</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m--> <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=114'>115</a>\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key)\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=115'>116</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures \u001b[39mand\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures:\n\u001b[1;32m    <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=116'>117</a>\u001b[0m         value \u001b[39m=\u001b[39m decode_nested_example(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures[key], value) \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/GCX/lib/python3.9/collections/__init__.py:1058\u001b[0m, in \u001b[0;36mUserDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/collections/__init__.py?line=1055'>1056</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m__missing__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/collections/__init__.py?line=1056'>1057</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__missing__\u001b[39m(\u001b[39mself\u001b[39m, key)\n\u001b[0;32m-> <a href='file:///home/lyn/.conda/envs/GCX/lib/python3.9/collections/__init__.py?line=1057'>1058</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'audio'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "import datasets\n",
    "# dataset_train = load_dataset(\"timit_asr\", split=\"train\")\n",
    "# dataset_test = load_dataset(\"timit_asr\", split=\"test\")\n",
    "# dataset = dataset_train.sort(\"id\")\n",
    "# dataset = dataset_test.sort(\"id\")\n",
    "# sampling_rate = dataset_train.features[\"audio\"].sampling_rate\n",
    "\n",
    "# processor = Wav2Vec2Processor.from_pretrained(\"facebook/data2vec-audio-base-960h\")\n",
    "# small_train_dataset = dataset_train.map(prepare_dataset,remove_columns=dataset_test.column_names).select(range(1000))\n",
    "# small_eval_dataset = dataset_test.map(prepare_dataset,remove_columns=dataset_test.column_names).select(range(100))\n",
    "\n",
    "\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset \n",
    "import importlib\n",
    "importlib.reload(dataset)\n",
    "\n",
    "dataset = dataset.LibriSpeech(16, 16)\n",
    "# dataset.prepare_data()\n",
    "dataset.setup()\n",
    "# train_loader = dataset.test_dataloader()\n",
    "# batch = next(iter(train_loader))\n",
    "# dataset.dataset['train'][0]['audio']['array']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LibriSpeech' object has no attribute 'splits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/lyn/speech_autoencoder/resynthesis.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.192.122/home/lyn/speech_autoencoder/resynthesis.ipynb#ch0000007vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mnext\u001b[39m(dataset\u001b[39m.\u001b[39;49mval_dataloader())\n",
      "File \u001b[0;32m~/speech_autoencoder/dataset.py:147\u001b[0m, in \u001b[0;36mLibriSpeech.val_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=145'>146</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mval_dataloader\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/lyn/speech_autoencoder/dataset.py?line=146'>147</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m DataLoader(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplits[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m], batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_batch_size, collate_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollate_fn)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LibriSpeech' object has no attribute 'splits'"
     ]
    }
   ],
   "source": [
    "next(dataset.val_dataloader())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Metrics and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Some weights of the model checkpoint at facebook/data2vec-audio-base-960h were not used when initializing Data2VecAudioModel: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing Data2VecAudioModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Data2VecAudioModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import models.SpeechAutoEncoder as SAE\n",
    "importlib.reload(SAE)\n",
    "\n",
    "decoder_configuration = AutoConfig.from_pretrained(\"jaketae/hifigan-lj-v1\", trust_remote_code=True,        \n",
    "        upsample_rates=[2, 2, 2, 2, 2, 2, 5],\n",
    "        upsample_initial_channel=768,\n",
    "        upsample_kernel_sizes=[2, 2, 3, 3, 3, 3, 10],\n",
    "        model_in_dim=768,\n",
    "        sampling_rate=16000)\n",
    "model = SAE.SpeechAutoEncoder(None,decoder_configuration,torch.nn.SmoothL1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'seed_everything' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available())\n\u001b[0;32m----> 3\u001b[0m seed_everything(\u001b[39m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m      6\u001b[0m checkpoint_callback \u001b[39m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m      7\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     dirpath\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./experiments\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     save_last\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed_everything' is not defined"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"1\"\n",
    "print(torch.cuda.is_available())\n",
    "seed_everything(42)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath=\"./experiments\",\n",
    "    filename='{epoch:02d}-{val_loss:.6f}',\n",
    "    save_top_k=10,\n",
    "    save_last=True,\n",
    "    mode='min')\n",
    "callbacks = [checkpoint_callback]\n",
    "tb_logger = pl_loggers.TensorBoardLogger(\"./experiments\")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=1000,\n",
    "    gpus=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "trainer.fit(model, dataset)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ad04a6bab26adf168611711eb7ba54f40351171452c3d4c6c22dc9c08a3f31d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch18')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
